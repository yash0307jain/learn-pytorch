{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Workflow\n",
    "\n",
    "Let's explore an example PyTorch end-to-end worflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'data {prepare and load}',\n",
       " 2: 'build model',\n",
       " 3: 'fitting the model to data (training)',\n",
       " 4: 'making predictions',\n",
       " 5: 'saving and loading the model',\n",
       " 6: 'putting it all together'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "what_were_covering = {\n",
    "    1: \"data {prepare and load}\",\n",
    "    2: \"build model\",\n",
    "    3: \"fitting the model to data (training)\",\n",
    "    4: \"making predictions\",\n",
    "    5: \"saving and loading the model\",\n",
    "    6: \"putting it all together\"\n",
    "}\n",
    "\n",
    "what_were_covering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn ## nn contains all of PyTorch's building blocks for neural netowrks\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# check PyTorch version\n",
    "torch.__version__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data (preparing and loading)\n",
    "\n",
    "Data can be almost anything... in machine learning.\n",
    "\n",
    "* Excel spreadsheet\n",
    "* Images of nay kind\n",
    "* Videos (YouTube has lots of data...)\n",
    "* Audio like songs or podcasts\n",
    "* DNA\n",
    "* Text\n",
    "\n",
    "Machine learning is a game of two parts:\n",
    "1. Get data into a numerical representation.\n",
    "2. Build a model to learn patterns in that numerical presentation.\n",
    "\n",
    "To showcase this, let's create some *known* data using the linear regression formula (`y = mx + c -> where m is the slope and c is the y intercept`).\n",
    "\n",
    "We'll use a linear regression formula to make s straight line with *known* **parameters**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0000],\n",
       "         [0.0200],\n",
       "         [0.0400],\n",
       "         [0.0600],\n",
       "         [0.0800],\n",
       "         [0.1000],\n",
       "         [0.1200],\n",
       "         [0.1400],\n",
       "         [0.1600],\n",
       "         [0.1800]]),\n",
       " tensor([[0.3000],\n",
       "         [0.3140],\n",
       "         [0.3280],\n",
       "         [0.3420],\n",
       "         [0.3560],\n",
       "         [0.3700],\n",
       "         [0.3840],\n",
       "         [0.3980],\n",
       "         [0.4120],\n",
       "         [0.4260]]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create *known* parameters\n",
    "weight = 0.7\n",
    "bias = 0.3\n",
    "\n",
    "# create data\n",
    "start = 0\n",
    "end = 1\n",
    "step = 0.02\n",
    "X = torch.arange(start, end, step).unsqueeze(dim=1)\n",
    "y = weight * X + bias\n",
    "\n",
    "X[:10], y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 50)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X), len(y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting data into training and test sets (one of the most important concepts in machine learning in general)\n",
    "\n",
    "Let's create a training and test set with our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 40, 10, 10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a train/test split\n",
    "train_split = int(0.8 * len(X))\n",
    "X_train, y_train = X[:train_split], y[:train_split]\n",
    "X_test, y_test = X[train_split:], y[train_split:]\n",
    "\n",
    "len(X_train), len(y_train), len(X_test), len(y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How might we better visualize our data?\n",
    "\n",
    "This is where the data explorer's motto comes in!\n",
    "\n",
    "\"`Visualize, visualize visualize!`\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(train_data=X_train,\n",
    "                     train_labels=y_train,\n",
    "                     test_data=X_test,\n",
    "                     test_labels=y_test,\n",
    "                     predictions=None):\n",
    "    \"\"\"\n",
    "    Plots training data, test data and compares predictions.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 7))\n",
    "\n",
    "    # Plot training data in blue\n",
    "    plt.scatter(train_data, train_labels, c=\"b\", s=5, label=\"Training data\")\n",
    "\n",
    "    # Plot test data in green\n",
    "    plt.scatter(test_data, test_labels, c=\"g\", s=5, label=\"Test data\")\n",
    "\n",
    "    # Are there predictions?\n",
    "    if predictions is not None:\n",
    "        # Plot the predictions if they exist in red\n",
    "        plt.scatter(test_data, predictions, c=\"r\", s=5, label=\"Predictions\")\n",
    "\n",
    "    # Show the legend\n",
    "    plt.legend(prop={\"size\": 14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_predictions()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build Model\n",
    "\n",
    "Our first PyTorch model!\n",
    "\n",
    "This is very exciting... let's do it!\n",
    "\n",
    "What our model does:\n",
    "* Start with random values (weight & bias)\n",
    "* Look at training data and adjust the random values to better represebt (or get closer to) the ideal values (the weight and bias values we used to create the data)\n",
    "\n",
    "How does it do so?\n",
    "\n",
    "Through two main algorithms:\n",
    "1. Gradient descent\n",
    "2. Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create linear regression model class\n",
    "class LinearRegressionModel(nn.Module): # <- almost everything in PyTorch inherits from nn.Module\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.weights = nn.Parameter(torch.randn(1, # <- start with a random weight and try to adjust it to the ideal weight\n",
    "                                               requires_grad=True, # <- can this parameter be updated via gradient descent?\n",
    "                                               dtype=torch.float)) # <- PyTorch loves the datatype torch.float32\n",
    "        \n",
    "        self.bias = nn.Parameter(torch.randn(1, # <- start with a random weight and try to adjust it to the ideal weight\n",
    "                                             requires_grad=True, # <- can this parameter be updated via gradient descent?\n",
    "                                             dtype=torch.float)) # <- PyTorch loves the datatype torch.float32\n",
    "        \n",
    "    # forward method to define the computation in the model\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor: # <- \"x\" is the input data\n",
    "        return self.weights * x + self.bias # this is the linear regression formula"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch model building essentials\n",
    "\n",
    "* `torch.nn` - contains all of the building blocks for computational graphs (a neural network can be consider a computaional graph)\n",
    "* `torch.nn.Parameter` - what parameters should out model try and learn, often a PyTorch layer from torch.nn will set these for us\n",
    "* `torch.nn.Module` - the base class for all neural network modules, if you subclass it, you should overwrite forward\n",
    "* `torch.optim` - this is where the optimizers in PyTroch live, they will help with gradient descent\n",
    "* `def forward()` - all nn.Module subclasses require you to overwrite forward(), this method defines what happens in the forward computation\n",
    "\n",
    "More of these essential modules via the PyTorch cheatsheet - https://pytorch.org/tutorials/beginner/ptcheat.html"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the contents of our PyTorch model\n",
    "\n",
    "Now we've created a model, let's see what's inside...\n",
    "\n",
    "So we can check our model parameters or what's inside our model using `.parameters()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([0.3367], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.1288], requires_grad=True)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a random seed\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# create an instance of the model (this is a subclass of nn.Module)\n",
    "model_0 = LinearRegressionModel()\n",
    "\n",
    "# check out the parameters\n",
    "list(model_0.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weights', tensor([0.3367])), ('bias', tensor([0.1288]))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list named parameters\n",
    "model_0.state_dict()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions using `torch.inference.mode()`\n",
    "\n",
    "To check our model's predictive power, let's see how well it predicts `y_test` based on `X_test`\n",
    "\n",
    "When we pass data throught our model, it's going to run it throught the `forward()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3982],\n",
       "        [0.4049],\n",
       "        [0.4116],\n",
       "        [0.4184],\n",
       "        [0.4251],\n",
       "        [0.4318],\n",
       "        [0.4386],\n",
       "        [0.4453],\n",
       "        [0.4520],\n",
       "        [0.4588]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make predictions with model\n",
    "with torch.inference_mode():\n",
    "    y_preds = model_0(X_test)\n",
    "\n",
    "# you can also do something similar with torch.no_grad(), however, torch.inference_mode() is preferred\n",
    "# with torch.no_grad():\n",
    "#     y_preds = model_0(X_test)\n",
    "\n",
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_predictions(predictions=y_preds)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train model\n",
    "\n",
    "The whole idea of training is for a model to move from some *unknown* parameters (these may be random) to some *known* parameters.\n",
    "\n",
    "Or in other words from a poor representation of the data tot a better representation of the data.\n",
    "\n",
    "One way to measure how poor or how wrong your models predictions are is to use a loss function.\n",
    "\n",
    "* Note: Loss function may also be called cost function or criterion in different areas.\n",
    "\n",
    "Things we need to train:\n",
    "\n",
    "* **Loss functions:** A function to measure how wrong your model's predictions are to the ideal outputs, lower is better.\n",
    "* **Optimizer:** Takes into account the loss of a model and adjusts the models's parameters (e.b. weights & bias) to improve the loss function.\n",
    "    * Inside the optimizer you'll often have to set two parameters:\n",
    "        * `params` - the model parametrs you'd like to optmizer, for example `params=model_0.parameters()`\n",
    "        * `lr (learning rate)` - the learning rate is a hyperparamete that defines how big/small the optmizer changes the parameters with each step (a small `lr` results in small changes, a large `lr` results in large changes)\n",
    "\n",
    "And specifically for PyTorch, we need:\n",
    "1. A training loop\n",
    "2. A testing loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([0.3367], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.1288], requires_grad=True)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model_0.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weights', tensor([0.3367])), ('bias', tensor([0.1288]))])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checkout our model's parameters (a parameter is a value that the model sets itself)\n",
    "model_0.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup a loss function\n",
    "loss_fn = nn.L1Loss()\n",
    "\n",
    "# setup an optimizer (stochastic gradient descent)\n",
    "optimizer = torch.optim.SGD(params=model_0.parameters(),\n",
    "                            lr=0.01) # lr = lerning rate = possibly the most important hyperparameter you can set"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Which loss function and optmizer should we use?\n",
    "\n",
    "**A:** This will be problem specific. But with experience, you'll get an idea of what works and what doesn't with your particular problem set.\n",
    "\n",
    "For example, for a regression problem (like this one), a loss function of `nn.L1Loss()` and the optmizer like `torch.optim.SGD()` will suffice.\n",
    "\n",
    "But for a classification problem like classifying whether a photo is of a dog or a cat, you'll likely waht to use a loss function of `nn.BCELoss()` (binary cross entripy loss)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a training loop (and a testing loop) in PyTorch\n",
    "\n",
    "A couple of things we need in a training loop:\n",
    "0. Loop throught the data\n",
    "1. Forward pass (this involves data moving throught our model's `forward()` functions) to make predictions on data - also called **forward propagation**\n",
    "2. Calculate the loss (compare forward pass predictions to groud truth labels)\n",
    "3. Optmizer zero grad\n",
    "4. Loss backward - move backwards thought network to calculate the gradient of each of the parameters of our model with respect to the loss (**backpropagation**)\n",
    "5. Optmizer step - use the optimizer to adjust our model's paramaters to try and improve the loss (**gradient descent**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([0.3367], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.1288], requires_grad=True)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model_0.eval().parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([0.3367], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.1288], requires_grad=True)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list((model_0.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weights', tensor([0.3367])), ('bias', tensor([0.1288]))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Loss: 0.31288138031959534\n",
      "OrderedDict([('weights', tensor([0.3406])), ('bias', tensor([0.1388]))])\n",
      "Epoch: 1\n",
      "Loss: 0.3013603389263153\n",
      "OrderedDict([('weights', tensor([0.3445])), ('bias', tensor([0.1488]))])\n",
      "Epoch: 2\n",
      "Loss: 0.28983935713768005\n",
      "OrderedDict([('weights', tensor([0.3484])), ('bias', tensor([0.1588]))])\n",
      "Epoch: 3\n",
      "Loss: 0.2783183455467224\n",
      "OrderedDict([('weights', tensor([0.3523])), ('bias', tensor([0.1688]))])\n",
      "Epoch: 4\n",
      "Loss: 0.26679736375808716\n",
      "OrderedDict([('weights', tensor([0.3562])), ('bias', tensor([0.1788]))])\n",
      "Epoch: 5\n",
      "Loss: 0.2552763521671295\n",
      "OrderedDict([('weights', tensor([0.3601])), ('bias', tensor([0.1888]))])\n",
      "Epoch: 6\n",
      "Loss: 0.24375534057617188\n",
      "OrderedDict([('weights', tensor([0.3640])), ('bias', tensor([0.1988]))])\n",
      "Epoch: 7\n",
      "Loss: 0.23223432898521423\n",
      "OrderedDict([('weights', tensor([0.3679])), ('bias', tensor([0.2088]))])\n",
      "Epoch: 8\n",
      "Loss: 0.22071333229541779\n",
      "OrderedDict([('weights', tensor([0.3718])), ('bias', tensor([0.2188]))])\n",
      "Epoch: 9\n",
      "Loss: 0.20919232070446014\n",
      "OrderedDict([('weights', tensor([0.3757])), ('bias', tensor([0.2288]))])\n",
      "Epoch: 10\n",
      "Loss: 0.1976713240146637\n",
      "OrderedDict([('weights', tensor([0.3796])), ('bias', tensor([0.2388]))])\n",
      "Epoch: 11\n",
      "Loss: 0.18615034222602844\n",
      "OrderedDict([('weights', tensor([0.3835])), ('bias', tensor([0.2488]))])\n",
      "Epoch: 12\n",
      "Loss: 0.1746293306350708\n",
      "OrderedDict([('weights', tensor([0.3874])), ('bias', tensor([0.2588]))])\n",
      "Epoch: 13\n",
      "Loss: 0.16310831904411316\n",
      "OrderedDict([('weights', tensor([0.3913])), ('bias', tensor([0.2688]))])\n",
      "Epoch: 14\n",
      "Loss: 0.1515873372554779\n",
      "OrderedDict([('weights', tensor([0.3952])), ('bias', tensor([0.2788]))])\n",
      "Epoch: 15\n",
      "Loss: 0.14006634056568146\n",
      "OrderedDict([('weights', tensor([0.3991])), ('bias', tensor([0.2888]))])\n",
      "Epoch: 16\n",
      "Loss: 0.1285453587770462\n",
      "OrderedDict([('weights', tensor([0.4030])), ('bias', tensor([0.2988]))])\n",
      "Epoch: 17\n",
      "Loss: 0.11702437698841095\n",
      "OrderedDict([('weights', tensor([0.4069])), ('bias', tensor([0.3088]))])\n",
      "Epoch: 18\n",
      "Loss: 0.1060912236571312\n",
      "OrderedDict([('weights', tensor([0.4108])), ('bias', tensor([0.3178]))])\n",
      "Epoch: 19\n",
      "Loss: 0.09681282937526703\n",
      "OrderedDict([('weights', tensor([0.4146])), ('bias', tensor([0.3258]))])\n",
      "Epoch: 20\n",
      "Loss: 0.08908725529909134\n",
      "OrderedDict([('weights', tensor([0.4184])), ('bias', tensor([0.3333]))])\n",
      "Epoch: 21\n",
      "Loss: 0.08227583020925522\n",
      "OrderedDict([('weights', tensor([0.4222])), ('bias', tensor([0.3403]))])\n",
      "Epoch: 22\n",
      "Loss: 0.07638873159885406\n",
      "OrderedDict([('weights', tensor([0.4258])), ('bias', tensor([0.3463]))])\n",
      "Epoch: 23\n",
      "Loss: 0.07160007208585739\n",
      "OrderedDict([('weights', tensor([0.4293])), ('bias', tensor([0.3518]))])\n",
      "Epoch: 24\n",
      "Loss: 0.06747636198997498\n",
      "OrderedDict([('weights', tensor([0.4328])), ('bias', tensor([0.3568]))])\n",
      "Epoch: 25\n",
      "Loss: 0.06395438313484192\n",
      "OrderedDict([('weights', tensor([0.4361])), ('bias', tensor([0.3613]))])\n",
      "Epoch: 26\n",
      "Loss: 0.06097004562616348\n",
      "OrderedDict([('weights', tensor([0.4394])), ('bias', tensor([0.3653]))])\n",
      "Epoch: 27\n",
      "Loss: 0.05845819041132927\n",
      "OrderedDict([('weights', tensor([0.4425])), ('bias', tensor([0.3688]))])\n",
      "Epoch: 28\n",
      "Loss: 0.05635259300470352\n",
      "OrderedDict([('weights', tensor([0.4455])), ('bias', tensor([0.3718]))])\n",
      "Epoch: 29\n",
      "Loss: 0.0545857734978199\n",
      "OrderedDict([('weights', tensor([0.4483])), ('bias', tensor([0.3743]))])\n",
      "Epoch: 30\n",
      "Loss: 0.053148526698350906\n",
      "OrderedDict([('weights', tensor([0.4512])), ('bias', tensor([0.3768]))])\n",
      "Epoch: 31\n",
      "Loss: 0.05181945487856865\n",
      "OrderedDict([('weights', tensor([0.4539])), ('bias', tensor([0.3788]))])\n",
      "Epoch: 32\n",
      "Loss: 0.05069301277399063\n",
      "OrderedDict([('weights', tensor([0.4564])), ('bias', tensor([0.3803]))])\n",
      "Epoch: 33\n",
      "Loss: 0.049822848290205\n",
      "OrderedDict([('weights', tensor([0.4590])), ('bias', tensor([0.3818]))])\n",
      "Epoch: 34\n",
      "Loss: 0.04895269125699997\n",
      "OrderedDict([('weights', tensor([0.4615])), ('bias', tensor([0.3833]))])\n",
      "Epoch: 35\n",
      "Loss: 0.04819351062178612\n",
      "OrderedDict([('weights', tensor([0.4639])), ('bias', tensor([0.3843]))])\n",
      "Epoch: 36\n",
      "Loss: 0.047531817108392715\n",
      "OrderedDict([('weights', tensor([0.4662])), ('bias', tensor([0.3853]))])\n",
      "Epoch: 37\n",
      "Loss: 0.04692792519927025\n",
      "OrderedDict([('weights', tensor([0.4684])), ('bias', tensor([0.3858]))])\n",
      "Epoch: 38\n",
      "Loss: 0.04642331600189209\n",
      "OrderedDict([('weights', tensor([0.4706])), ('bias', tensor([0.3863]))])\n",
      "Epoch: 39\n",
      "Loss: 0.04591871052980423\n",
      "OrderedDict([('weights', tensor([0.4728])), ('bias', tensor([0.3868]))])\n",
      "Epoch: 40\n",
      "Loss: 0.04543796554207802\n",
      "OrderedDict([('weights', tensor([0.4748])), ('bias', tensor([0.3868]))])\n",
      "Epoch: 41\n",
      "Loss: 0.04503796249628067\n",
      "OrderedDict([('weights', tensor([0.4768])), ('bias', tensor([0.3868]))])\n",
      "Epoch: 42\n",
      "Loss: 0.044637955725193024\n",
      "OrderedDict([('weights', tensor([0.4788])), ('bias', tensor([0.3868]))])\n",
      "Epoch: 43\n",
      "Loss: 0.04423796385526657\n",
      "OrderedDict([('weights', tensor([0.4808])), ('bias', tensor([0.3868]))])\n",
      "Epoch: 44\n",
      "Loss: 0.043837957084178925\n",
      "OrderedDict([('weights', tensor([0.4828])), ('bias', tensor([0.3868]))])\n",
      "Epoch: 45\n",
      "Loss: 0.04343796148896217\n",
      "OrderedDict([('weights', tensor([0.4848])), ('bias', tensor([0.3868]))])\n",
      "Epoch: 46\n",
      "Loss: 0.043074630200862885\n",
      "OrderedDict([('weights', tensor([0.4866])), ('bias', tensor([0.3863]))])\n",
      "Epoch: 47\n",
      "Loss: 0.04272563382983208\n",
      "OrderedDict([('weights', tensor([0.4884])), ('bias', tensor([0.3858]))])\n",
      "Epoch: 48\n",
      "Loss: 0.04237663000822067\n",
      "OrderedDict([('weights', tensor([0.4902])), ('bias', tensor([0.3853]))])\n",
      "Epoch: 49\n",
      "Loss: 0.04202762991189957\n",
      "OrderedDict([('weights', tensor([0.4920])), ('bias', tensor([0.3848]))])\n",
      "Epoch: 50\n",
      "Loss: 0.04167863354086876\n",
      "OrderedDict([('weights', tensor([0.4938])), ('bias', tensor([0.3843]))])\n",
      "Epoch: 51\n",
      "Loss: 0.04132963344454765\n",
      "OrderedDict([('weights', tensor([0.4956])), ('bias', tensor([0.3838]))])\n",
      "Epoch: 52\n",
      "Loss: 0.04098063334822655\n",
      "OrderedDict([('weights', tensor([0.4974])), ('bias', tensor([0.3833]))])\n",
      "Epoch: 53\n",
      "Loss: 0.04063162952661514\n",
      "OrderedDict([('weights', tensor([0.4992])), ('bias', tensor([0.3828]))])\n",
      "Epoch: 54\n",
      "Loss: 0.040282636880874634\n",
      "OrderedDict([('weights', tensor([0.5010])), ('bias', tensor([0.3823]))])\n",
      "Epoch: 55\n",
      "Loss: 0.039933644235134125\n",
      "OrderedDict([('weights', tensor([0.5028])), ('bias', tensor([0.3818]))])\n",
      "Epoch: 56\n",
      "Loss: 0.03958464413881302\n",
      "OrderedDict([('weights', tensor([0.5046])), ('bias', tensor([0.3813]))])\n",
      "Epoch: 57\n",
      "Loss: 0.03923564404249191\n",
      "OrderedDict([('weights', tensor([0.5064])), ('bias', tensor([0.3808]))])\n",
      "Epoch: 58\n",
      "Loss: 0.03888664394617081\n",
      "OrderedDict([('weights', tensor([0.5082])), ('bias', tensor([0.3803]))])\n",
      "Epoch: 59\n",
      "Loss: 0.0385376438498497\n",
      "OrderedDict([('weights', tensor([0.5100])), ('bias', tensor([0.3798]))])\n",
      "Epoch: 60\n",
      "Loss: 0.03818932920694351\n",
      "OrderedDict([('weights', tensor([0.5116])), ('bias', tensor([0.3788]))])\n",
      "Epoch: 61\n",
      "Loss: 0.03785243630409241\n",
      "OrderedDict([('weights', tensor([0.5134])), ('bias', tensor([0.3783]))])\n",
      "Epoch: 62\n",
      "Loss: 0.0375034399330616\n",
      "OrderedDict([('weights', tensor([0.5152])), ('bias', tensor([0.3778]))])\n",
      "Epoch: 63\n",
      "Loss: 0.037164121866226196\n",
      "OrderedDict([('weights', tensor([0.5168])), ('bias', tensor([0.3768]))])\n",
      "Epoch: 64\n",
      "Loss: 0.03681822493672371\n",
      "OrderedDict([('weights', tensor([0.5186])), ('bias', tensor([0.3763]))])\n",
      "Epoch: 65\n",
      "Loss: 0.03647511452436447\n",
      "OrderedDict([('weights', tensor([0.5202])), ('bias', tensor([0.3753]))])\n",
      "Epoch: 66\n",
      "Loss: 0.036133039742708206\n",
      "OrderedDict([('weights', tensor([0.5220])), ('bias', tensor([0.3748]))])\n",
      "Epoch: 67\n",
      "Loss: 0.03578609973192215\n",
      "OrderedDict([('weights', tensor([0.5236])), ('bias', tensor([0.3738]))])\n",
      "Epoch: 68\n",
      "Loss: 0.03544783592224121\n",
      "OrderedDict([('weights', tensor([0.5254])), ('bias', tensor([0.3733]))])\n",
      "Epoch: 69\n",
      "Loss: 0.035098835825920105\n",
      "OrderedDict([('weights', tensor([0.5272])), ('bias', tensor([0.3728]))])\n",
      "Epoch: 70\n",
      "Loss: 0.03476089984178543\n",
      "OrderedDict([('weights', tensor([0.5288])), ('bias', tensor([0.3718]))])\n",
      "Epoch: 71\n",
      "Loss: 0.03441363573074341\n",
      "OrderedDict([('weights', tensor([0.5306])), ('bias', tensor([0.3713]))])\n",
      "Epoch: 72\n",
      "Loss: 0.03407188132405281\n",
      "OrderedDict([('weights', tensor([0.5322])), ('bias', tensor([0.3703]))])\n",
      "Epoch: 73\n",
      "Loss: 0.03372843936085701\n",
      "OrderedDict([('weights', tensor([0.5340])), ('bias', tensor([0.3698]))])\n",
      "Epoch: 74\n",
      "Loss: 0.03338287025690079\n",
      "OrderedDict([('weights', tensor([0.5355])), ('bias', tensor([0.3688]))])\n",
      "Epoch: 75\n",
      "Loss: 0.033043231815099716\n",
      "OrderedDict([('weights', tensor([0.5373])), ('bias', tensor([0.3683]))])\n",
      "Epoch: 76\n",
      "Loss: 0.03269423171877861\n",
      "OrderedDict([('weights', tensor([0.5391])), ('bias', tensor([0.3678]))])\n",
      "Epoch: 77\n",
      "Loss: 0.03235765919089317\n",
      "OrderedDict([('weights', tensor([0.5407])), ('bias', tensor([0.3668]))])\n",
      "Epoch: 78\n",
      "Loss: 0.03200903534889221\n",
      "OrderedDict([('weights', tensor([0.5425])), ('bias', tensor([0.3663]))])\n",
      "Epoch: 79\n",
      "Loss: 0.03166865184903145\n",
      "OrderedDict([('weights', tensor([0.5441])), ('bias', tensor([0.3653]))])\n",
      "Epoch: 80\n",
      "Loss: 0.03132382780313492\n",
      "OrderedDict([('weights', tensor([0.5459])), ('bias', tensor([0.3648]))])\n",
      "Epoch: 81\n",
      "Loss: 0.030979638919234276\n",
      "OrderedDict([('weights', tensor([0.5475])), ('bias', tensor([0.3638]))])\n",
      "Epoch: 82\n",
      "Loss: 0.030638623982667923\n",
      "OrderedDict([('weights', tensor([0.5493])), ('bias', tensor([0.3633]))])\n",
      "Epoch: 83\n",
      "Loss: 0.0302906334400177\n",
      "OrderedDict([('weights', tensor([0.5509])), ('bias', tensor([0.3623]))])\n",
      "Epoch: 84\n",
      "Loss: 0.029953425750136375\n",
      "OrderedDict([('weights', tensor([0.5527])), ('bias', tensor([0.3618]))])\n",
      "Epoch: 85\n",
      "Loss: 0.02960442565381527\n",
      "OrderedDict([('weights', tensor([0.5545])), ('bias', tensor([0.3613]))])\n",
      "Epoch: 86\n",
      "Loss: 0.029265422374010086\n",
      "OrderedDict([('weights', tensor([0.5561])), ('bias', tensor([0.3603]))])\n",
      "Epoch: 87\n",
      "Loss: 0.028919225558638573\n",
      "OrderedDict([('weights', tensor([0.5579])), ('bias', tensor([0.3598]))])\n",
      "Epoch: 88\n",
      "Loss: 0.028576409444212914\n",
      "OrderedDict([('weights', tensor([0.5595])), ('bias', tensor([0.3588]))])\n",
      "Epoch: 89\n",
      "Loss: 0.028234023600816727\n",
      "OrderedDict([('weights', tensor([0.5613])), ('bias', tensor([0.3583]))])\n",
      "Epoch: 90\n",
      "Loss: 0.02788740023970604\n",
      "OrderedDict([('weights', tensor([0.5629])), ('bias', tensor([0.3573]))])\n",
      "Epoch: 91\n",
      "Loss: 0.02754882536828518\n",
      "OrderedDict([('weights', tensor([0.5647])), ('bias', tensor([0.3568]))])\n",
      "Epoch: 92\n",
      "Loss: 0.027199819684028625\n",
      "OrderedDict([('weights', tensor([0.5665])), ('bias', tensor([0.3563]))])\n",
      "Epoch: 93\n",
      "Loss: 0.026862185448408127\n",
      "OrderedDict([('weights', tensor([0.5681])), ('bias', tensor([0.3553]))])\n",
      "Epoch: 94\n",
      "Loss: 0.02651461958885193\n",
      "OrderedDict([('weights', tensor([0.5699])), ('bias', tensor([0.3548]))])\n",
      "Epoch: 95\n",
      "Loss: 0.026173178106546402\n",
      "OrderedDict([('weights', tensor([0.5715])), ('bias', tensor([0.3538]))])\n",
      "Epoch: 96\n",
      "Loss: 0.025829419493675232\n",
      "OrderedDict([('weights', tensor([0.5733])), ('bias', tensor([0.3533]))])\n",
      "Epoch: 97\n",
      "Loss: 0.025484168902039528\n",
      "OrderedDict([('weights', tensor([0.5748])), ('bias', tensor([0.3523]))])\n",
      "Epoch: 98\n",
      "Loss: 0.025144215673208237\n",
      "OrderedDict([('weights', tensor([0.5766])), ('bias', tensor([0.3518]))])\n",
      "Epoch: 99\n",
      "Loss: 0.02479521930217743\n",
      "OrderedDict([('weights', tensor([0.5784])), ('bias', tensor([0.3513]))])\n",
      "Epoch: 100\n",
      "Loss: 0.024458957836031914\n",
      "OrderedDict([('weights', tensor([0.5800])), ('bias', tensor([0.3503]))])\n",
      "Epoch: 101\n",
      "Loss: 0.024110015481710434\n",
      "OrderedDict([('weights', tensor([0.5818])), ('bias', tensor([0.3498]))])\n",
      "Epoch: 102\n",
      "Loss: 0.02376994863152504\n",
      "OrderedDict([('weights', tensor([0.5834])), ('bias', tensor([0.3488]))])\n",
      "Epoch: 103\n",
      "Loss: 0.02342480979859829\n",
      "OrderedDict([('weights', tensor([0.5852])), ('bias', tensor([0.3483]))])\n",
      "Epoch: 104\n",
      "Loss: 0.023080939427018166\n",
      "OrderedDict([('weights', tensor([0.5868])), ('bias', tensor([0.3473]))])\n",
      "Epoch: 105\n",
      "Loss: 0.022739609703421593\n",
      "OrderedDict([('weights', tensor([0.5886])), ('bias', tensor([0.3468]))])\n",
      "Epoch: 106\n",
      "Loss: 0.022391926497220993\n",
      "OrderedDict([('weights', tensor([0.5902])), ('bias', tensor([0.3458]))])\n",
      "Epoch: 107\n",
      "Loss: 0.022054409608244896\n",
      "OrderedDict([('weights', tensor([0.5920])), ('bias', tensor([0.3453]))])\n",
      "Epoch: 108\n",
      "Loss: 0.02170540764927864\n",
      "OrderedDict([('weights', tensor([0.5938])), ('bias', tensor([0.3448]))])\n",
      "Epoch: 109\n",
      "Loss: 0.02136671543121338\n",
      "OrderedDict([('weights', tensor([0.5954])), ('bias', tensor([0.3438]))])\n",
      "Epoch: 110\n",
      "Loss: 0.021020209416747093\n",
      "OrderedDict([('weights', tensor([0.5972])), ('bias', tensor([0.3433]))])\n",
      "Epoch: 111\n",
      "Loss: 0.020677711814641953\n",
      "OrderedDict([('weights', tensor([0.5988])), ('bias', tensor([0.3423]))])\n",
      "Epoch: 112\n",
      "Loss: 0.020335007458925247\n",
      "OrderedDict([('weights', tensor([0.6006])), ('bias', tensor([0.3418]))])\n",
      "Epoch: 113\n",
      "Loss: 0.01998869702219963\n",
      "OrderedDict([('weights', tensor([0.6022])), ('bias', tensor([0.3408]))])\n",
      "Epoch: 114\n",
      "Loss: 0.019649803638458252\n",
      "OrderedDict([('weights', tensor([0.6040])), ('bias', tensor([0.3403]))])\n",
      "Epoch: 115\n",
      "Loss: 0.019300809130072594\n",
      "OrderedDict([('weights', tensor([0.6058])), ('bias', tensor([0.3398]))])\n",
      "Epoch: 116\n",
      "Loss: 0.018963487818837166\n",
      "OrderedDict([('weights', tensor([0.6074])), ('bias', tensor([0.3388]))])\n",
      "Epoch: 117\n",
      "Loss: 0.01861559972167015\n",
      "OrderedDict([('weights', tensor([0.6092])), ('bias', tensor([0.3383]))])\n",
      "Epoch: 118\n",
      "Loss: 0.018274478614330292\n",
      "OrderedDict([('weights', tensor([0.6108])), ('bias', tensor([0.3373]))])\n",
      "Epoch: 119\n",
      "Loss: 0.01793040707707405\n",
      "OrderedDict([('weights', tensor([0.6126])), ('bias', tensor([0.3368]))])\n",
      "Epoch: 120\n",
      "Loss: 0.01758546754717827\n",
      "OrderedDict([('weights', tensor([0.6141])), ('bias', tensor([0.3358]))])\n",
      "Epoch: 121\n",
      "Loss: 0.017245199531316757\n",
      "OrderedDict([('weights', tensor([0.6159])), ('bias', tensor([0.3353]))])\n",
      "Epoch: 122\n",
      "Loss: 0.016896454617381096\n",
      "OrderedDict([('weights', tensor([0.6175])), ('bias', tensor([0.3343]))])\n",
      "Epoch: 123\n",
      "Loss: 0.01656000316143036\n",
      "OrderedDict([('weights', tensor([0.6193])), ('bias', tensor([0.3338]))])\n",
      "Epoch: 124\n",
      "Loss: 0.016210999339818954\n",
      "OrderedDict([('weights', tensor([0.6211])), ('bias', tensor([0.3333]))])\n",
      "Epoch: 125\n",
      "Loss: 0.01587124727666378\n",
      "OrderedDict([('weights', tensor([0.6227])), ('bias', tensor([0.3323]))])\n",
      "Epoch: 126\n",
      "Loss: 0.015525800175964832\n",
      "OrderedDict([('weights', tensor([0.6245])), ('bias', tensor([0.3318]))])\n",
      "Epoch: 127\n",
      "Loss: 0.015182236209511757\n",
      "OrderedDict([('weights', tensor([0.6261])), ('bias', tensor([0.3308]))])\n",
      "Epoch: 128\n",
      "Loss: 0.014840595424175262\n",
      "OrderedDict([('weights', tensor([0.6279])), ('bias', tensor([0.3303]))])\n",
      "Epoch: 129\n",
      "Loss: 0.01449323259294033\n",
      "OrderedDict([('weights', tensor([0.6295])), ('bias', tensor([0.3293]))])\n",
      "Epoch: 130\n",
      "Loss: 0.014155392535030842\n",
      "OrderedDict([('weights', tensor([0.6313])), ('bias', tensor([0.3288]))])\n",
      "Epoch: 131\n",
      "Loss: 0.013806397095322609\n",
      "OrderedDict([('weights', tensor([0.6331])), ('bias', tensor([0.3283]))])\n",
      "Epoch: 132\n",
      "Loss: 0.013468015007674694\n",
      "OrderedDict([('weights', tensor([0.6347])), ('bias', tensor([0.3273]))])\n",
      "Epoch: 133\n",
      "Loss: 0.013121193274855614\n",
      "OrderedDict([('weights', tensor([0.6365])), ('bias', tensor([0.3268]))])\n",
      "Epoch: 134\n",
      "Loss: 0.01277900766581297\n",
      "OrderedDict([('weights', tensor([0.6381])), ('bias', tensor([0.3258]))])\n",
      "Epoch: 135\n",
      "Loss: 0.012435990385711193\n",
      "OrderedDict([('weights', tensor([0.6399])), ('bias', tensor([0.3253]))])\n",
      "Epoch: 136\n",
      "Loss: 0.012089998461306095\n",
      "OrderedDict([('weights', tensor([0.6415])), ('bias', tensor([0.3243]))])\n",
      "Epoch: 137\n",
      "Loss: 0.01175079494714737\n",
      "OrderedDict([('weights', tensor([0.6433])), ('bias', tensor([0.3238]))])\n",
      "Epoch: 138\n",
      "Loss: 0.011401789262890816\n",
      "OrderedDict([('weights', tensor([0.6451])), ('bias', tensor([0.3233]))])\n",
      "Epoch: 139\n",
      "Loss: 0.011064786463975906\n",
      "OrderedDict([('weights', tensor([0.6467])), ('bias', tensor([0.3223]))])\n",
      "Epoch: 140\n",
      "Loss: 0.010716588236391544\n",
      "OrderedDict([('weights', tensor([0.6485])), ('bias', tensor([0.3218]))])\n",
      "Epoch: 141\n",
      "Loss: 0.010375780053436756\n",
      "OrderedDict([('weights', tensor([0.6501])), ('bias', tensor([0.3208]))])\n",
      "Epoch: 142\n",
      "Loss: 0.010031387209892273\n",
      "OrderedDict([('weights', tensor([0.6519])), ('bias', tensor([0.3203]))])\n",
      "Epoch: 143\n",
      "Loss: 0.00968676432967186\n",
      "OrderedDict([('weights', tensor([0.6534])), ('bias', tensor([0.3193]))])\n",
      "Epoch: 144\n",
      "Loss: 0.00934618804603815\n",
      "OrderedDict([('weights', tensor([0.6552])), ('bias', tensor([0.3188]))])\n",
      "Epoch: 145\n",
      "Loss: 0.008997755125164986\n",
      "OrderedDict([('weights', tensor([0.6568])), ('bias', tensor([0.3178]))])\n",
      "Epoch: 146\n",
      "Loss: 0.008660982362926006\n",
      "OrderedDict([('weights', tensor([0.6586])), ('bias', tensor([0.3173]))])\n",
      "Epoch: 147\n",
      "Loss: 0.008311985060572624\n",
      "OrderedDict([('weights', tensor([0.6604])), ('bias', tensor([0.3168]))])\n",
      "Epoch: 148\n",
      "Loss: 0.007972546853125095\n",
      "OrderedDict([('weights', tensor([0.6620])), ('bias', tensor([0.3158]))])\n",
      "Epoch: 149\n",
      "Loss: 0.007626786828041077\n",
      "OrderedDict([('weights', tensor([0.6638])), ('bias', tensor([0.3153]))])\n",
      "Epoch: 150\n",
      "Loss: 0.0072835348546504974\n",
      "OrderedDict([('weights', tensor([0.6654])), ('bias', tensor([0.3143]))])\n",
      "Epoch: 151\n",
      "Loss: 0.0069415816105902195\n",
      "OrderedDict([('weights', tensor([0.6672])), ('bias', tensor([0.3138]))])\n",
      "Epoch: 152\n",
      "Loss: 0.006594527512788773\n",
      "OrderedDict([('weights', tensor([0.6688])), ('bias', tensor([0.3128]))])\n",
      "Epoch: 153\n",
      "Loss: 0.006256377790123224\n",
      "OrderedDict([('weights', tensor([0.6706])), ('bias', tensor([0.3123]))])\n",
      "Epoch: 154\n",
      "Loss: 0.005907378159463406\n",
      "OrderedDict([('weights', tensor([0.6724])), ('bias', tensor([0.3118]))])\n",
      "Epoch: 155\n",
      "Loss: 0.005569314118474722\n",
      "OrderedDict([('weights', tensor([0.6740])), ('bias', tensor([0.3108]))])\n",
      "Epoch: 156\n",
      "Loss: 0.005222179926931858\n",
      "OrderedDict([('weights', tensor([0.6758])), ('bias', tensor([0.3103]))])\n",
      "Epoch: 157\n",
      "Loss: 0.004880307707935572\n",
      "OrderedDict([('weights', tensor([0.6774])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 158\n",
      "Loss: 0.004536977503448725\n",
      "OrderedDict([('weights', tensor([0.6792])), ('bias', tensor([0.3088]))])\n",
      "Epoch: 159\n",
      "Loss: 0.00419129803776741\n",
      "OrderedDict([('weights', tensor([0.6808])), ('bias', tensor([0.3078]))])\n",
      "Epoch: 160\n",
      "Loss: 0.003851778106763959\n",
      "OrderedDict([('weights', tensor([0.6826])), ('bias', tensor([0.3073]))])\n",
      "Epoch: 161\n",
      "Loss: 0.0035027742851525545\n",
      "OrderedDict([('weights', tensor([0.6844])), ('bias', tensor([0.3068]))])\n",
      "Epoch: 162\n",
      "Loss: 0.0031660839449614286\n",
      "OrderedDict([('weights', tensor([0.6860])), ('bias', tensor([0.3058]))])\n",
      "Epoch: 163\n",
      "Loss: 0.0028175704646855593\n",
      "OrderedDict([('weights', tensor([0.6878])), ('bias', tensor([0.3053]))])\n",
      "Epoch: 164\n",
      "Loss: 0.002477074507623911\n",
      "OrderedDict([('weights', tensor([0.6894])), ('bias', tensor([0.3043]))])\n",
      "Epoch: 165\n",
      "Loss: 0.0021323724649846554\n",
      "OrderedDict([('weights', tensor([0.6912])), ('bias', tensor([0.3038]))])\n",
      "Epoch: 166\n",
      "Loss: 0.0017880633240565658\n",
      "OrderedDict([('weights', tensor([0.6927])), ('bias', tensor([0.3028]))])\n",
      "Epoch: 167\n",
      "Loss: 0.0014518297975882888\n",
      "OrderedDict([('weights', tensor([0.6947])), ('bias', tensor([0.3028]))])\n",
      "Epoch: 168\n",
      "Loss: 0.0011887758737429976\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 169\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 170\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 171\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 172\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 173\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 174\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 175\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 176\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 177\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 178\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 179\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 180\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 181\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 182\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 183\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 184\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 185\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 186\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 187\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 188\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 189\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 190\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 191\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 192\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 193\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 194\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 195\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 196\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 197\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 198\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 199\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 200\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 201\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 202\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 203\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 204\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 205\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 206\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 207\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 208\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 209\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 210\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 211\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 212\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 213\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 214\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 215\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 216\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 217\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 218\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 219\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 220\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 221\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 222\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 223\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 224\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 225\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 226\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 227\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 228\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 229\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 230\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 231\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 232\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 233\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 234\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 235\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 236\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 237\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 238\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 239\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 240\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 241\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 242\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 243\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 244\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 245\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 246\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 247\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 248\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 249\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 250\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 251\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 252\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 253\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 254\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 255\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 256\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 257\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 258\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 259\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 260\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 261\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 262\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 263\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 264\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 265\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 266\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 267\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 268\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 269\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 270\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 271\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 272\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 273\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 274\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 275\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 276\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 277\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 278\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 279\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 280\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 281\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 282\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 283\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 284\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 285\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 286\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 287\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 288\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 289\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 290\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 291\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 292\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 293\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 294\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 295\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 296\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 297\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 298\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 299\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 300\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 301\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 302\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 303\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 304\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 305\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 306\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 307\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 308\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 309\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 310\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 311\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 312\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 313\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 314\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 315\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 316\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 317\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 318\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 319\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 320\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 321\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 322\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 323\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 324\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 325\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 326\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 327\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 328\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 329\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 330\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 331\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 332\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 333\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 334\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 335\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 336\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 337\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 338\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 339\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 340\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 341\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 342\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 343\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 344\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 345\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 346\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 347\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 348\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 349\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 350\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 351\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 352\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 353\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 354\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 355\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 356\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 357\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 358\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 359\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 360\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 361\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 362\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 363\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 364\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 365\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 366\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 367\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 368\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 369\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 370\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 371\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 372\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 373\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 374\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 375\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 376\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 377\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 378\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 379\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 380\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 381\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 382\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 383\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 384\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 385\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 386\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 387\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 388\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 389\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 390\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 391\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 392\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 393\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 394\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 395\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 396\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 397\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 398\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 399\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 400\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 401\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 402\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 403\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 404\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 405\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 406\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 407\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 408\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 409\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 410\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 411\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 412\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 413\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 414\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 415\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 416\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 417\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 418\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 419\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 420\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 421\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 422\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 423\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 424\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 425\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 426\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 427\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 428\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 429\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 430\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 431\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 432\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 433\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 434\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 435\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 436\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 437\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 438\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 439\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 440\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 441\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 442\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 443\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 444\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 445\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 446\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 447\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 448\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 449\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 450\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 451\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 452\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 453\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 454\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 455\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 456\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 457\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 458\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 459\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 460\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 461\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 462\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 463\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 464\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 465\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 466\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 467\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 468\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 469\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 470\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 471\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 472\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 473\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 474\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 475\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 476\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 477\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 478\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 479\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 480\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 481\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 482\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 483\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 484\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 485\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 486\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 487\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 488\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 489\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 490\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 491\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 492\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 493\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 494\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 495\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 496\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 497\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 498\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 499\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 500\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 501\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 502\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 503\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 504\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 505\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 506\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 507\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 508\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 509\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 510\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 511\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 512\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 513\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 514\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 515\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 516\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 517\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 518\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 519\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 520\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 521\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 522\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 523\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 524\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 525\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 526\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 527\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 528\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 529\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 530\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 531\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 532\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 533\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 534\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 535\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 536\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 537\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 538\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 539\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 540\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 541\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 542\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 543\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 544\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 545\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 546\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 547\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 548\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 549\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 550\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 551\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 552\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 553\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 554\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 555\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 556\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 557\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 558\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 559\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 560\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 561\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 562\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 563\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 564\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 565\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 566\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 567\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 568\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 569\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 570\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 571\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 572\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 573\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 574\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 575\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 576\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 577\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 578\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 579\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 580\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 581\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 582\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 583\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 584\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 585\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 586\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 587\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 588\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 589\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 590\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 591\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 592\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 593\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 594\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 595\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 596\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 597\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 598\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 599\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 600\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 601\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 602\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 603\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 604\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 605\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 606\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 607\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 608\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 609\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 610\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 611\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 612\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 613\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 614\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 615\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 616\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 617\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 618\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 619\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 620\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 621\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 622\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 623\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 624\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 625\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 626\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 627\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 628\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 629\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 630\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 631\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 632\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 633\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 634\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 635\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 636\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 637\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 638\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 639\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 640\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 641\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 642\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 643\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 644\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 645\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 646\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 647\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 648\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 649\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 650\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 651\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 652\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 653\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 654\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 655\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 656\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 657\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 658\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 659\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 660\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 661\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 662\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 663\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 664\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 665\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 666\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 667\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 668\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 669\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 670\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 671\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 672\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 673\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 674\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 675\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 676\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 677\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 678\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 679\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 680\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 681\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 682\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 683\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 684\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 685\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 686\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 687\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 688\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 689\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 690\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 691\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 692\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 693\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 694\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 695\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 696\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 697\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 698\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 699\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 700\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 701\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 702\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 703\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 704\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 705\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 706\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 707\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 708\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 709\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 710\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 711\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 712\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 713\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 714\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 715\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 716\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 717\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 718\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 719\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 720\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 721\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 722\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 723\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 724\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 725\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 726\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 727\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 728\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 729\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 730\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 731\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 732\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 733\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 734\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 735\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 736\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 737\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 738\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 739\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 740\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 741\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 742\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 743\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 744\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 745\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 746\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 747\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 748\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 749\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 750\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 751\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 752\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 753\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 754\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 755\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 756\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 757\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 758\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 759\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 760\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 761\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 762\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 763\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 764\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 765\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 766\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 767\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 768\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 769\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 770\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 771\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 772\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 773\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 774\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 775\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 776\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 777\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 778\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 779\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 780\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 781\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 782\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 783\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 784\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 785\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 786\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 787\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 788\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 789\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 790\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 791\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 792\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 793\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 794\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 795\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 796\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 797\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 798\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 799\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 800\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 801\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 802\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 803\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 804\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 805\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 806\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 807\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 808\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 809\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 810\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 811\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 812\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 813\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 814\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 815\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 816\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 817\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 818\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 819\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 820\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 821\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 822\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 823\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 824\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 825\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 826\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 827\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 828\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 829\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 830\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 831\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 832\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 833\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 834\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 835\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 836\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 837\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 838\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 839\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 840\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 841\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 842\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 843\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 844\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 845\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 846\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 847\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 848\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 849\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 850\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 851\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 852\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 853\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 854\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 855\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 856\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 857\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 858\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 859\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 860\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 861\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 862\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 863\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 864\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 865\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 866\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 867\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 868\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 869\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 870\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 871\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 872\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 873\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 874\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 875\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 876\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 877\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 878\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 879\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 880\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 881\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 882\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 883\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 884\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 885\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 886\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 887\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 888\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 889\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 890\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 891\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 892\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 893\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 894\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 895\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 896\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 897\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 898\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 899\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 900\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 901\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 902\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 903\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 904\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 905\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 906\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 907\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 908\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 909\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 910\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 911\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 912\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 913\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 914\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 915\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 916\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 917\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 918\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 919\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 920\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 921\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 922\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 923\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 924\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 925\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 926\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 927\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 928\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 929\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 930\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 931\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 932\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 933\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 934\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 935\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 936\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 937\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 938\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 939\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 940\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 941\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 942\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 943\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 944\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 945\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 946\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 947\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 948\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 949\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 950\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 951\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 952\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 953\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 954\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 955\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 956\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 957\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 958\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 959\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 960\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 961\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 962\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 963\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 964\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 965\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 966\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 967\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 968\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 969\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 970\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 971\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 972\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 973\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 974\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 975\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 976\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 977\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 978\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 979\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 980\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 981\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 982\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 983\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 984\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 985\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 986\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 987\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 988\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 989\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 990\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 991\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 992\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 993\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 994\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 995\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 996\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 997\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
      "Epoch: 998\n",
      "Loss: 0.00893248151987791\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 999\n",
      "Loss: 0.0025885060895234346\n",
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# an epoch is one loop throught the data... (this is a hyperparameter because we've set it ourselves)\n",
    "epochs = 1000\n",
    "\n",
    "### Training\n",
    "# 1. loop thought the data\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch: {epoch}\")\n",
    "\n",
    "    # set the model to training mode\n",
    "    model_0.train() # train mode in PyTorch sets all paramaters that require gradients to require gradients\n",
    "\n",
    "    # 1. forward pass\n",
    "    y_pred = model_0(X_train)\n",
    "\n",
    "    # 2. calculate the loss\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "    print(f\"Loss: {loss}\")\n",
    "\n",
    "    # 3. optmizer zero grad\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 4. perform backpropagration on the loss with respect tot he paramters of the model\n",
    "    loss.backward()\n",
    "\n",
    "    # 5. step the optmizer (perform gradient descent)\n",
    "    optimizer.step() # by default how the optimizer changes will acculumate throught the loop so... we have to zero them above in step 3 for the next iteration of the loop\n",
    "\n",
    "    # Testing\n",
    "    model_0.eval() # turns off gradient tracking\n",
    "\n",
    "    # print out the model state_dict()\n",
    "    print(model_0.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8685],\n",
       "        [0.8825],\n",
       "        [0.8965],\n",
       "        [0.9105],\n",
       "        [0.9245],\n",
       "        [0.9384],\n",
       "        [0.9524],\n",
       "        [0.9664],\n",
       "        [0.9804],\n",
       "        [0.9944]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.inference_mode():\n",
    "    y_preds = model_0(X_test)\n",
    "\n",
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_predictions(predictions=y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
