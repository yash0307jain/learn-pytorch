{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "_U-Y2wZu9lBm"
      },
      "source": [
        "### To check which gpu we are using if any available\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PywUmz4uoVFA",
        "outputId": "63596acd-2522-4689-e428-b7e3da0a3fe6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "zsh:1: command not found: nvidia-smi\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "FAYh6amZn1Bi"
      },
      "source": [
        "# 00. Pytorch Fundamentals\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pZzldWp7i2C",
        "outputId": "c8fc7a51-f8f0-47ab-fd7d-416d4ce46ca4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.13.1\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='mps')"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device(\"mps\")\n",
        "device"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "YEdvvoVs8vj3"
      },
      "source": [
        "## Introduction to Tensors\n",
        "\n",
        "### Creating tensors\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MzazmbapTKY",
        "outputId": "a405cb39-7ffa-4036-97df-c4f091a103d6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(7)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# scalar\n",
        "scalar = torch.tensor(7)\n",
        "scalar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckwk9dZkxVWp",
        "outputId": "b237c7fe-53f5-4db3-8582-eee1ec3e3c08"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# scalar dimention\n",
        "scalar.ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnEl8z9cx3mV",
        "outputId": "01d52d5c-e574-4317-efe6-7fa2c7bd5d11"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# get tensor back as python int\n",
        "scalar.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lkR-KFlzQEW",
        "outputId": "18eddc53-0119-45c1-f57f-4aa7fb21b963"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "scalar.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVF-Vaz9yEBY",
        "outputId": "368389d4-9749-489d-e11c-5be49714abe4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([7, 7])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# vector\n",
        "vector = torch.tensor([7, 7])\n",
        "vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-zRfr2Qy7T8",
        "outputId": "cbc805ee-a795-468a-bd30-3979ba054103"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# vector dimention\n",
        "vector.ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUmuUcnpzA4w",
        "outputId": "cf8f9983-38b0-490d-e704-c40ce504c495"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vector.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FoQZV8TOzER7",
        "outputId": "7bed7d27-157c-4795-c0fe-d54be3b94ad3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 7,  8],\n",
              "        [ 9, 10]])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# MATRIX\n",
        "MATRIX = torch.tensor([[7, 8], [9, 10]])\n",
        "MATRIX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gf6B7Gd9zfFC",
        "outputId": "9a77d876-5dc8-4a5d-e9dc-7bf2c932b97e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# MATRIX dimension\n",
        "MATRIX.ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIcl8hA7zk5N",
        "outputId": "518dd28a-94e1-4efd-ef3b-4fb8b63b2ea6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 9, 10])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "MATRIX[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKN6EgHmzmjt",
        "outputId": "60d633ac-6356-4edc-a394-96f058c37d84"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 2])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "MATRIX.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ox9MpmVGzny9",
        "outputId": "44e6bf12-67d0-48fe-b776-97ba783a9b94"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[1, 2, 3],\n",
              "         [3, 6, 9],\n",
              "         [2, 4, 5]]])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# TENSOR\n",
        "TENSOR = torch.tensor([[[1, 2, 3], [3, 6, 9], [2, 4, 5]]])\n",
        "TENSOR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BOQOQYjz5If",
        "outputId": "24195ebb-73a9-4484-c91a-65883ef604a7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# TENSOR dimension\n",
        "TENSOR.ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qA1x_VAIz8Nc",
        "outputId": "087bbef8-4f51-4168-e986-4d80c06752c3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 3])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "TENSOR.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYw683Um0HiG",
        "outputId": "78dcb75c-b685-418a-cee4-aef1ff77b3df"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [3, 6, 9],\n",
              "        [2, 4, 5]])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "TENSOR[0]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "wRKn7I2n0lc2"
      },
      "source": [
        "### Random Tensors\n",
        "\n",
        "Why random tensors?\n",
        "\n",
        "Random tensors are important because the way many neural networks learn is that they start with tensors full of random numbers and then adjust those random numbers to better represent the data.\n",
        "\n",
        "`Start with random numbers -> look at data -> update random numbers -> look at data -> update random numbers`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VekOnRyH8pwE",
        "outputId": "6b5b65fa-fd46-4ca6-d356-9c1afa415138"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.7032, 0.7166, 0.2751, 0.1896],\n",
              "        [0.9922, 0.5990, 0.3384, 0.2770],\n",
              "        [0.5911, 0.5510, 0.7761, 0.7752]])"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create random tensor of shape (3, 4)\n",
        "random_tensor = torch.rand(3, 4)\n",
        "random_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zrt183V1-Pxp",
        "outputId": "559d03a4-6d75-4a4e-cc26-a9a96cad4ac4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# shape of the random tensor\n",
        "random_tensor.ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgMxgHKC-EH3",
        "outputId": "5d41b3c3-ed54-41bc-dcbe-278522441686"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([3, 244, 244]), 3)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a random tensor with similar shape to an image tensor\n",
        "random_image_size_tensor = torch.rand(size=(3, 244, 244))  # color channels (R, G, B), height, width\n",
        "random_image_size_tensor.shape, random_image_size_tensor.ndim"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "49IkbNdi_D5l"
      },
      "source": [
        "### Zero and Ones\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfQZWgP3grN1",
        "outputId": "f3277089-51df-4723-cd71-972677a17208"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.]])"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# create a tensor of all zeros\n",
        "zeros = torch.zeros(size=(3, 4))\n",
        "zeros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPEeILjJg2bO",
        "outputId": "1407c16f-4e91-41be-db1e-6459e2867649"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.]])"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "zeros * random_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SUMf7x8hAgI",
        "outputId": "f5f655f3-37a3-4299-a1e4-ce1c083c9c2a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.]])"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# create tensor of all ones\n",
        "ones = torch.ones(size=(3, 4))\n",
        "ones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "xbue3OsFhK14"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ones.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "random_tensor.dtype"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Creating a range of tensors and tensors-like\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# use torch.range() and get deprecated message, use torch.arange()\n",
        "one_to_ten = torch.arange(1, 11)\n",
        "one_to_ten"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([  0,  77, 154, 231, 308, 385, 462, 539, 616, 693, 770, 847, 924])"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "one_to_ten = torch.arange(start=0, end=1000, step=77)\n",
        "one_to_ten"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "one_to_ten = torch.arange(start=1, end=11, step=1)\n",
        "one_to_ten"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# creating tensors like\n",
        "ten_zeros = torch.zeros_like(input=one_to_ten)\n",
        "ten_zeros"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tensor datatypes\n",
        "\n",
        "**Note:** Tensor datatypes is one of the 3 big errors you'll run into with PyTorch & deep learning:\n",
        "\n",
        "1. Tensors not right datatype\n",
        "2. Tensors not right shape\n",
        "3. Tensors not on the right device\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([3., 6., 9.])"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# float 32 tensor\n",
        "float_32_tensor = torch.tensor(\n",
        "    [3.0, 6.0, 9.0],\n",
        "    dtype=None,  # what datatype is the tensor (e.g. float32, float16, etc)\n",
        "    device=None,  # what device is your tensor on\n",
        "    requires_grad=False,\n",
        ")  # whether or not to track gradients with this tensors operations\n",
        "float_32_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "float_32_tensor.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([3., 6., 9.], dtype=torch.float16)"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# convert 32 bit tensor to the float 16 tensor\n",
        "float_16_tensor = float_32_tensor.type(torch.float16)\n",
        "float_16_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 9., 36., 81.])"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# this is one of the pytorch caveats,\n",
        "# we might thing this will through an error but instead it works fine and will return the multiplication of float32 type\n",
        "float_16_tensor * float_32_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([3, 6, 9], dtype=torch.int32)"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "int_32_tensor = torch.tensor([3, 6, 9], dtype=torch.int32)\n",
        "int_32_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 9., 36., 81.])"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "float_32_tensor * int_32_tensor"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Getting information fromn tensors (tensor attributes)\n",
        "\n",
        "1. Tensors not right datatype - to get datatype from a tensor, can use `tensor.dtype`\n",
        "2. Tensors not right shape - to get shape from a tensor, can use `tensor.shape` or `tensor.size()`\n",
        "3. Tensors not on the right device - to get device from a tensor, can use `tensor.device`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.0771, 0.5063, 0.2284, 0.4250],\n",
              "        [0.4012, 0.9556, 0.7727, 0.4563],\n",
              "        [0.3597, 0.6202, 0.1297, 0.4020]])"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a tensor\n",
        "some_tensor = torch.rand(3, 4)\n",
        "some_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Some tensor: tensor([[0.0771, 0.5063, 0.2284, 0.4250],\n",
            "        [0.4012, 0.9556, 0.7727, 0.4563],\n",
            "        [0.3597, 0.6202, 0.1297, 0.4020]])\n",
            "Datatype of tensor: torch.float32\n",
            "Shape of tensor: torch.Size([3, 4])\n",
            "Device of tensor: cpu\n"
          ]
        }
      ],
      "source": [
        "# find out details about some tensor\n",
        "print(f\"Some tensor: {some_tensor}\")\n",
        "print(f\"Datatype of tensor: {some_tensor.dtype}\")\n",
        "print(f\"Shape of tensor: {some_tensor.shape}\")\n",
        "print(f\"Device of tensor: {some_tensor.device}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Manipulating tensors (tensor operations)\n",
        "\n",
        "Tensor operations include:\n",
        "\n",
        "-   Addition\n",
        "-   Subtraction\n",
        "-   Mulitplication (element-wise)\n",
        "-   Divison\n",
        "-   Matrix multiplication\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([11, 12, 13])"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# create a tensor and add 10 to it\n",
        "tensor = torch.tensor([1, 2, 3])\n",
        "tensor + 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([10, 20, 30])"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# multiply tensor by 10\n",
        "tensor * 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([-9, -8, -7])"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# subtract 10\n",
        "tensor - 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([10, 20, 30])"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Try out PyTorch in-built function\n",
        "torch.mul(tensor, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([11, 12, 13])"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.add(tensor, 10)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Matrix multiplication\n",
        "\n",
        "Two main ways of performing multiplication in neural neworks and deep learning:\n",
        "\n",
        "1. Element-wise multiplication\n",
        "2. Matrix multiplication (dot product)\n",
        "\n",
        "There are two main rules that performing matrix multiplication need to satisfy:\n",
        "\n",
        "1. The **inner dimensions** must match:\n",
        "\n",
        "-   `(3, 2) @ (3, 2)` won't work\n",
        "-   `(2, 3) @ (3, 2)` will work\n",
        "-   `(3, 2) @ (2, 3)` will work\n",
        "\n",
        "2. The resulting matrix has the shape of the **outer dimensions**\n",
        "\n",
        "-   `(2, 3) @ (3, 2)` -> `(2, 2)`\n",
        "-   `(3, 2) @ (2, 3)` -> `(3, 3)`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1, 2, 3]) * tensor([1, 2, 3]) = tensor([1, 4, 9])\n"
          ]
        }
      ],
      "source": [
        "# element wise multiplication\n",
        "print(f\"{tensor} * {tensor} = {tensor * tensor}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# matrix multiplication\n",
        "torch.matmul(tensor, tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# matrix multiplication by hand\n",
        "1 * 1 + 2 * 2 + 3 * 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8.51 µs ± 105 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "value = 0\n",
        "for i in range(len(tensor)):\n",
        "    value += tensor[i] * tensor[i]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "745 ns ± 7.75 ns per loop (mean ± std. dev. of 7 runs, 1,000,000 loops each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "value = torch.matmul(tensor, tensor)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### One of the most common errors in deep learning: shape errors\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[50], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m torch\u001b[39m.\u001b[39;49mmatmul(torch\u001b[39m.\u001b[39;49mrand(\u001b[39m3\u001b[39;49m, \u001b[39m2\u001b[39;49m), torch\u001b[39m.\u001b[39;49mrand(\u001b[39m3\u001b[39;49m, \u001b[39m2\u001b[39;49m))\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
          ]
        }
      ],
      "source": [
        "torch.matmul(torch.rand(3, 2), torch.rand(3, 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.8536, 0.8351],\n",
              "        [0.8615, 0.8716]])"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.matmul(torch.rand(2, 3), torch.rand(3, 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([3, 3])"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.matmul(torch.rand(3, 2), torch.rand(2, 3)).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([3, 3])"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.matmul(torch.rand(3, 10), torch.rand(10, 3)).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[54], line 10\u001b[0m\n\u001b[1;32m      5\u001b[0m tensor_B \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([[\u001b[39m7\u001b[39m, \u001b[39m10\u001b[39m],\n\u001b[1;32m      6\u001b[0m                          [\u001b[39m8\u001b[39m, \u001b[39m11\u001b[39m],\n\u001b[1;32m      7\u001b[0m                          [\u001b[39m9\u001b[39m, \u001b[39m12\u001b[39m]])\n\u001b[1;32m      9\u001b[0m \u001b[39m# torch.mm(tensor_A, tensor_B) # torch.mm is the same as torch.matmul (it's an alias for writing less code)\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m torch\u001b[39m.\u001b[39;49mmatmul(tensor_A, tensor_B)\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
          ]
        }
      ],
      "source": [
        "# shapes for matrix multiplication\n",
        "tensor_A = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
        "tensor_B = torch.tensor([[7, 10], [8, 11], [9, 12]])\n",
        "\n",
        "# torch.mm(tensor_A, tensor_B) # torch.mm is the same as torch.matmul (it's an alias for writing less code)\n",
        "torch.matmul(tensor_A, tensor_B)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([3, 2]), torch.Size([3, 2]))"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor_A.shape, tensor_B.shape"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### To fix our tensor shape issues, we can manipulate the shape of one of our tensors using a **transpose**.\n",
        "\n",
        "A **transpose** switches the axes or dimensions of a given tensor.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 7,  8,  9],\n",
              "        [10, 11, 12]])"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor_B.T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 7, 10],\n",
              "        [ 8, 11],\n",
              "        [ 9, 12]])"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor_B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([2, 3]), torch.Size([3, 2]))"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor_B.T.shape, tensor_B.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([3, 2]), torch.Size([2, 3]))"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor_A.shape, tensor_B.T.shape  # inner dimensions are same now after transpose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original shapes: \n",
            "tensor_A = torch.Size([3, 2]), tensor_B = torch.Size([3, 2])\n",
            "\n",
            "New shapes: \n",
            "tensor_A = torch.Size([3, 2]), tensor_B = torch.Size([2, 3])\n",
            "\n",
            "Multiplication: \n",
            "torch.Size([3, 2]) @ torch.Size([2, 3]) <- inner dimensions must match\n",
            "\n",
            "Output:\n",
            "tensor([[ 27,  30,  33],\n",
            "        [ 61,  68,  75],\n",
            "        [ 95, 106, 117]])\n",
            "\n",
            "Output shape: \n",
            "torch.Size([3, 3])\n"
          ]
        }
      ],
      "source": [
        "# the matrix multiplication operation works when tensor_B trasposed\n",
        "print(f\"Original shapes: \\ntensor_A = {tensor_A.shape}, tensor_B = {tensor_B.shape}\")\n",
        "print(f\"\\nNew shapes: \\ntensor_A = {tensor_A.shape}, tensor_B = {tensor_B.T.shape}\")\n",
        "print(f\"\\nMultiplication: \\n{tensor_A.shape} @ {tensor_B.T.shape} <- inner dimensions must match\")\n",
        "print(f\"\\nOutput:\")\n",
        "output = torch.matmul(tensor_A, tensor_B.T)\n",
        "print(output)\n",
        "print(f\"\\nOutput shape: \\n{output.shape}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Finding the min, max, mean, sum, etc (tensor aggregation)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91])"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# create a tensor\n",
        "x = torch.arange(1, 100, 10)\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(1), tensor(1))"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# find the min\n",
        "torch.min(x), x.min()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(91), tensor(91))"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# find the max\n",
        "torch.max(x), x.max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.int64"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(46., dtype=torch.float16), tensor(46., dtype=torch.float16))"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# find the mean - note: the torch.mean() function requires a tensor of not int or long, it should be of type float\n",
        "torch.mean(x, dtype=torch.float16), x.mean(dtype=torch.float16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(46., dtype=torch.float16), tensor(46., dtype=torch.float16))"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.mean(x.type(torch.float16)), x.type(torch.float16).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(460), tensor(460))"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# find the sum\n",
        "torch.sum(x), x.sum()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Finding the positional min max max\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91])"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(0)"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# fint the position in tensor that has the minimum value with argmin() -> returns index postiion of target tensor where the minimum value occurs\n",
        "x.argmin()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(1)"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(9)"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# finf the positions in tensor that has the maximum value with argmax() -> returns index position of target tensor where the maximum value occurs\n",
        "x.argmax()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(91)"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x[9]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reshaping, stacking, squeezing and unsqueezing tensors\n",
        "\n",
        "-   `Reshaping` - reshapes an input tensor to a defined shape\n",
        "-   `View` - return a view of an input tensor of certain shape but keep the same memory as the original tensor\n",
        "-   `Stacking` - combine multiple tensors on top of each other (vstack) or side by size (hstack)\n",
        "-   `Squeeze` - removes all `1` dimension from a tensor\n",
        "-   `Unsqueeze` - add a `1` dimension to a target tensor\n",
        "-   `Permute` - return a view of the input with dimension permnuted (swapped) in a certain way\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]), torch.Size([9]), torch.float32)"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# create a tensor\n",
        "import torch\n",
        "\n",
        "x = torch.arange(1.0, 10.0)\n",
        "x, x.shape, x.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# add an extra dimension\n",
        "x_reshaped = x.reshape(1, 9)\n",
        "x_reshaped, x_reshaped.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# change the view\n",
        "z = x.view(1, 9)\n",
        "z, z.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]]),\n",
              " tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.]))"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# changing z changes x (because a view of a tensor share the same memory as the original input)\n",
        "z[:, 0] = 5\n",
        "z, x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
              "        [5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
              "        [5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
              "        [5., 2., 3., 4., 5., 6., 7., 8., 9.]])"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# stack tensors on top of each other\n",
        "x_stacked = torch.stack([x, x, x, x], dim=0)\n",
        "x_stacked"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Previous tensor: tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]])\n",
            "Previous shape: torch.Size([1, 9])\n",
            "\n",
            "New tensor: tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
            "New shape: torch.Size([9])\n"
          ]
        }
      ],
      "source": [
        "# torch.squeeze() -  removes all single dimensions from a target tensor\n",
        "print(f\"Previous tensor: {x_reshaped}\")\n",
        "print(f\"Previous shape: {x_reshaped.shape}\")\n",
        "\n",
        "# remove extra dimensions from x_reshaped\n",
        "x_squeezed = x_reshaped.squeeze()\n",
        "print(f\"\\nNew tensor: {x_squeezed}\")\n",
        "print(f\"New shape: {x_squeezed.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_reshaped, x_reshaped.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.]), torch.Size([9]))"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_reshaped.squeeze(), x_reshaped.squeeze().shape  # shape has changed after squeeze method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Previous tensor: tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
            "Previous shape: torch.Size([9])\n",
            "\n",
            "New tensor: tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]])\n",
            "New shape: torch.Size([1, 9])\n"
          ]
        }
      ],
      "source": [
        "# torch.unsqueeze() - adds a single dimension to a target tensor at a specific dim (dimension)\n",
        "print(f\"Previous tensor: {x_squeezed}\")\n",
        "print(f\"Previous shape: {x_squeezed.shape}\")\n",
        "\n",
        "# add extra dimension from x_squeezed\n",
        "x_unsqueezed = x_squeezed.unsqueeze(dim=0)\n",
        "print(f\"\\nNew tensor: {x_unsqueezed}\")\n",
        "print(f\"New shape: {x_unsqueezed.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Previous shape: torch.Size([224, 224, 3])\n",
            "\n",
            "New shape: torch.Size([3, 224, 224])\n"
          ]
        }
      ],
      "source": [
        "# torch.permute - rearranges the dimensions of a target tensor in a specified order\n",
        "x_original = torch.rand(size=(224, 224, 3))\n",
        "print(f\"Previous shape: {x_original.shape}\")  # [height, width, color_channels]\n",
        "\n",
        "# permute the original tensor to rearrange the axis (or dim) order\n",
        "# NOTE: x_permute will share the same memory as x_original as it is a view\n",
        "x_permute = torch.permute(x_original, (2, 0, 1))  # shifts axis 0->1, 1->2, 2->0\n",
        "print(f\"\\nNew shape: {x_permute.shape}\")  # [color_channels, height, width]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[[0.7984, 0.3735, 0.3664],\n",
              "          [0.0423, 0.3422, 0.7395],\n",
              "          [0.4664, 0.6891, 0.1590],\n",
              "          ...,\n",
              "          [0.2365, 0.3830, 0.8157],\n",
              "          [0.5002, 0.9659, 0.6456],\n",
              "          [0.8256, 0.4457, 0.6669]],\n",
              " \n",
              "         [[0.4898, 0.9465, 0.4107],\n",
              "          [0.9542, 0.0580, 0.8276],\n",
              "          [0.1960, 0.9609, 0.5473],\n",
              "          ...,\n",
              "          [0.3869, 0.9540, 0.2035],\n",
              "          [0.2028, 0.4482, 0.5278],\n",
              "          [0.2261, 0.7738, 0.6668]],\n",
              " \n",
              "         [[0.7937, 0.3735, 0.6957],\n",
              "          [0.7512, 0.6983, 0.1878],\n",
              "          [0.7385, 0.8701, 0.0046],\n",
              "          ...,\n",
              "          [0.4819, 0.5231, 0.8152],\n",
              "          [0.3794, 0.4082, 0.8096],\n",
              "          [0.1099, 0.9793, 0.9004]],\n",
              " \n",
              "         ...,\n",
              " \n",
              "         [[0.7677, 0.1041, 0.2972],\n",
              "          [0.3357, 0.0714, 0.0571],\n",
              "          [0.9330, 0.1015, 0.3439],\n",
              "          ...,\n",
              "          [0.8161, 0.3050, 0.7181],\n",
              "          [0.5624, 0.3873, 0.3187],\n",
              "          [0.2707, 0.8489, 0.4013]],\n",
              " \n",
              "         [[0.8475, 0.8979, 0.9573],\n",
              "          [0.4513, 0.6699, 0.0910],\n",
              "          [0.6502, 0.7852, 0.1111],\n",
              "          ...,\n",
              "          [0.7363, 0.9063, 0.9371],\n",
              "          [0.8363, 0.3321, 0.3923],\n",
              "          [0.8524, 0.0223, 0.0971]],\n",
              " \n",
              "         [[0.1768, 0.9752, 0.0874],\n",
              "          [0.7092, 0.1070, 0.1104],\n",
              "          [0.1591, 0.7667, 0.0600],\n",
              "          ...,\n",
              "          [0.0170, 0.2191, 0.5878],\n",
              "          [0.1041, 0.4429, 0.1515],\n",
              "          [0.7176, 0.2178, 0.3452]]]),\n",
              " torch.Size([224, 224, 3]))"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_original, x_original.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[[0.7984, 0.0423, 0.4664,  ..., 0.2365, 0.5002, 0.8256],\n",
              "          [0.4898, 0.9542, 0.1960,  ..., 0.3869, 0.2028, 0.2261],\n",
              "          [0.7937, 0.7512, 0.7385,  ..., 0.4819, 0.3794, 0.1099],\n",
              "          ...,\n",
              "          [0.7677, 0.3357, 0.9330,  ..., 0.8161, 0.5624, 0.2707],\n",
              "          [0.8475, 0.4513, 0.6502,  ..., 0.7363, 0.8363, 0.8524],\n",
              "          [0.1768, 0.7092, 0.1591,  ..., 0.0170, 0.1041, 0.7176]],\n",
              " \n",
              "         [[0.3735, 0.3422, 0.6891,  ..., 0.3830, 0.9659, 0.4457],\n",
              "          [0.9465, 0.0580, 0.9609,  ..., 0.9540, 0.4482, 0.7738],\n",
              "          [0.3735, 0.6983, 0.8701,  ..., 0.5231, 0.4082, 0.9793],\n",
              "          ...,\n",
              "          [0.1041, 0.0714, 0.1015,  ..., 0.3050, 0.3873, 0.8489],\n",
              "          [0.8979, 0.6699, 0.7852,  ..., 0.9063, 0.3321, 0.0223],\n",
              "          [0.9752, 0.1070, 0.7667,  ..., 0.2191, 0.4429, 0.2178]],\n",
              " \n",
              "         [[0.3664, 0.7395, 0.1590,  ..., 0.8157, 0.6456, 0.6669],\n",
              "          [0.4107, 0.8276, 0.5473,  ..., 0.2035, 0.5278, 0.6668],\n",
              "          [0.6957, 0.1878, 0.0046,  ..., 0.8152, 0.8096, 0.9004],\n",
              "          ...,\n",
              "          [0.2972, 0.0571, 0.3439,  ..., 0.7181, 0.3187, 0.4013],\n",
              "          [0.9573, 0.0910, 0.1111,  ..., 0.9371, 0.3923, 0.0971],\n",
              "          [0.0874, 0.1104, 0.0600,  ..., 0.5878, 0.1515, 0.3452]]]),\n",
              " torch.Size([3, 224, 224]))"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_permute = torch.permute(x_original, (2, 0, 1))\n",
        "x_permute, x_permute.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(0.7984), tensor(0.7984))"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_original[0, 0, 0], x_permute[0, 0, 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [],
      "source": [
        "# changing the value in the x_original changes the value of x_permute as well because they are sharing the same memory\n",
        "x_original[0, 0, 0] = 123"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(123.), tensor(123.))"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_original[0, 0, 0], x_permute[0, 0, 0]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Indexing (selecting data from tensors)\n",
        "\n",
        "Indexing with PyTorch is similar to indexing with NumPy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[[1, 2, 3],\n",
              "          [4, 5, 6],\n",
              "          [7, 8, 9]]]),\n",
              " torch.Size([1, 3, 3]))"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# create a tensor\n",
        "import torch\n",
        "\n",
        "x = torch.arange(1, 10).reshape(1, 3, 3)\n",
        "x, x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [4, 5, 6],\n",
              "        [7, 8, 9]])"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# lets index on our new tensor\n",
        "x[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# lets index on the middle bracket (dim=1)\n",
        "x[0][0]  # or x[0, 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(1)"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# lets index of the most inner bracket (last dimension)\n",
        "x[0][0][0]  # or x[0, 0, 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3]])"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# you can also use \":\" to select \"all\" of a target dimension\n",
        "x[:, 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[2, 5, 8]])"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# get all values of 0th and 1th dimensions but only index 1 of 2nd dimension\n",
        "x[:, :, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([5])"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# get all values of the 0th dimension but only the 1 index value of 1st and 2nd dimension\n",
        "x[:, 1, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# get index 0 of 0th and 1st dimension and all values of 2nd dimension\n",
        "x[0, 0, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([9]), tensor(9))"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# get index on x to return 9\n",
        "x[:, 2, 2], x[0, 2, 2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[3, 6, 9]])"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# get index on x to return 3, 6, 9\n",
        "x[:, :, 2]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## PyTorch tensors & NumPy\n",
        "\n",
        "NumPy is a popular scientific Python numerical computing library.\n",
        "\n",
        "And because of this, PyTorch has functionality to interact with it\n",
        "\n",
        "-   NumPy -> PyTorch tensor -> `torch.from_numpy(ndarray)`\n",
        "-   PyTorch tensor -> NumPy -> `torch.Tensor.numpy()`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([1., 2., 3., 4., 5., 6., 7.]),\n",
              " dtype('float64'),\n",
              " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64),\n",
              " torch.float64)"
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# numpy array to tensor\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "numpy_array = np.arange(1.0, 8.0)\n",
        "tensor = torch.from_numpy(\n",
        "    numpy_array\n",
        ")  # warning: when converting from numpy -> pytorch, pytorch reflects numpy's default datatype of float64 unless specified otherwise\n",
        "numpy_array, numpy_array.dtype, tensor, tensor.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([1., 2., 3., 4., 5., 6., 7.]),\n",
              " dtype('float64'),\n",
              " tensor([1., 2., 3., 4., 5., 6., 7.]),\n",
              " torch.float32)"
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "numpy_array = np.arange(1.0, 8.0)\n",
        "tensor = torch.from_numpy(numpy_array).type(torch.float32)\n",
        "numpy_array, numpy_array.dtype, tensor, tensor.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([2., 3., 4., 5., 6., 7., 8.]), tensor([1., 2., 3., 4., 5., 6., 7.]))"
            ]
          },
          "execution_count": 100,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# change the value of numpy_array, what will this do to `tensor`?\n",
        "numpy_array += 1\n",
        "numpy_array, tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([1., 1., 1., 1., 1., 1., 1.]),\n",
              " torch.float32,\n",
              " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32),\n",
              " dtype('float32'))"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# tensor to numpy array\n",
        "tensor = torch.ones(7)\n",
        "numpy_tensor = tensor.numpy()\n",
        "tensor, tensor.dtype, numpy_tensor, numpy_tensor.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([2., 2., 2., 2., 2., 2., 2.]),\n",
              " array([2., 2., 2., 2., 2., 2., 2.], dtype=float32))"
            ]
          },
          "execution_count": 102,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# change the tensor, what happens to `numpy_tensor`?\n",
        "tensor += 1\n",
        "tensor, numpy_tensor"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reproducibility (trying to take random out of random)\n",
        "\n",
        "In short how a neural network learns:\n",
        "\n",
        "`start with random numbers -> tensor operations -> update random numbers to try and make them better representations of the data -> again -> again -> again....`\n",
        "\n",
        "To reduce the randomness in neural networks and PyTorch comes the concept of a **random seed**.\n",
        "\n",
        "Essentially what the random seed does is \"flavour\" the randomness.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.4448, 0.5940, 0.0632, 0.9060],\n",
            "        [0.9641, 0.5537, 0.2008, 0.2464],\n",
            "        [0.2853, 0.2142, 0.5919, 0.8379]])\n",
            "tensor([[0.8156, 0.7058, 0.5042, 0.1880],\n",
            "        [0.8861, 0.9602, 0.7615, 0.3168],\n",
            "        [0.0941, 0.4364, 0.7853, 0.0538]])\n",
            "tensor([[False, False, False, False],\n",
            "        [False, False, False, False],\n",
            "        [False, False, False, False]])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# create two random tensors\n",
        "random_tensor_A = torch.rand(3, 4)\n",
        "random_tensor_B = torch.rand(3, 4)\n",
        "\n",
        "print(random_tensor_A)\n",
        "print(random_tensor_B)\n",
        "print(random_tensor_A == random_tensor_B)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
            "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
            "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
            "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
            "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
            "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
            "tensor([[True, True, True, True],\n",
            "        [True, True, True, True],\n",
            "        [True, True, True, True]])\n"
          ]
        }
      ],
      "source": [
        "# lets make some random but reproducible tensors\n",
        "import torch\n",
        "\n",
        "# set the random seed\n",
        "RANDOM_SEED = 42\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "random_tensor_C = torch.rand(3, 4)\n",
        "\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "random_tensor_D = torch.rand(3, 4)\n",
        "\n",
        "print(random_tensor_C)\n",
        "print(random_tensor_D)\n",
        "print(random_tensor_C == random_tensor_D)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Running tensors and PyTorch objects on the GPU's (and making faster computations)\n",
        "\n",
        "GPUs = faster computations on numbers, thanks to CUDA + NVIDIA hardware + PyTorch working behing the scenes to make everything hunky dory (good)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. Getting a GPU\n",
        "\n",
        "1. Easiest - Use Google Colab for a free GPU (options tp upgrade as well)\n",
        "2. Use your own GPU - takes a little bit of setup and requires the investment of purchasing a GPU, there's lots of options...\n",
        "3. Use cloud computing - GCP, AWS, Azure, these services allow you to rent computers on the cloud and access them\n",
        "\n",
        "For 2, 3 PyTorch + GPU drivers (CUDA) takes a little bit of setting up, to do this, refer to PyTorch setup documentation\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Check for GPU access with PyTorch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {},
      "outputs": [],
      "source": [
        "# check for GPU access with PyTorch\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: mps\n"
          ]
        }
      ],
      "source": [
        "# setup device agnostic code\n",
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\"  # NVIDIA GPU\n",
        "elif torch.backends.mps.is_available():\n",
        "    device = \"mps\"  # Apple GPU\n",
        "else:\n",
        "    device = \"cpu\"  # Defaults to CPU if NVIDIA GPU/Apple GPU aren't available\n",
        "\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {},
      "outputs": [],
      "source": [
        "# count number of devices - for NVIDEA\n",
        "# torch.cuda.device_count()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Putting tensors (and models) on the GPU\n",
        "\n",
        "The reason we want our tensors/models on the GPU is because using a GPU results in faster computations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1, 2, 3]) cpu\n"
          ]
        }
      ],
      "source": [
        "# creata a tensor (default on the CPU)\n",
        "tensor = torch.tensor([1, 2, 3])\n",
        "\n",
        "# tensor not on GPU\n",
        "print(tensor, tensor.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1, 2, 3], device='mps:0')"
            ]
          },
          "execution_count": 109,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# move tensor to GPU (if available)\n",
        "tensor_on_gpu = tensor.to(device)\n",
        "tensor_on_gpu"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. Moving tensors back to the CPU\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "can't convert mps:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[110], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# if tensor in on GPU, can't transfor it ot NumPy\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m tensor_on_gpu\u001b[39m.\u001b[39;49mnumpy()\n",
            "\u001b[0;31mTypeError\u001b[0m: can't convert mps:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
          ]
        }
      ],
      "source": [
        "# if tensor in on GPU, can't transfor it ot NumPy\n",
        "tensor_on_gpu.numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 2, 3])"
            ]
          },
          "execution_count": 111,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# to fix the GPU tensor with NumPy issue, we can first set it to the CPU\n",
        "tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()\n",
        "tensor_back_on_cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1, 2, 3], device='mps:0')"
            ]
          },
          "execution_count": 112,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor_on_gpu"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
